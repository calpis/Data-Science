{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Keras on Amazon's fine food review Part 1\n",
    "## Creating baseline models\n",
    "\n",
    "To analyze how effective neural network models are for this dataset, we will be creating a logistic regression model and a SVM model as baselines to compare accuracies.  For these, the dataset will be encoded using the straightforward bag of words method after removing stopwords using the list provided by nltk library.  There will also be some hyperparameter tuning to try to find the best possible fit of these models.  Afterwards, a bootstrap test will be done to assess a 99% confidence interval for the accuracy for these models.  By creating a confidence interval, we will be able to statistically prove whether the accuracy achieved by the neural network is significantly better than the baseline models or not.\n",
    "\n",
    "\n",
    "   The notebook will be organized as below:\n",
    "1. Create a bag of words representation to encode the text into numerical vectors.\n",
    "2. Use the numerical vectors and fit them onto a logistic regressor and SVM.\n",
    "3. Hyperparameter tuning on the baseline models will be done using sklearn's gridsearch method.\n",
    "4. Once the hyperparameters are tuned, the models will be trained and tested for accuracy multiple times. By doing this, a confidence interval of accuracies will be developed which will be used to test if the accuracy improvement seen in neural networks are significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data importing/wrangling\n",
    "import pandas as pd\n",
    "\n",
    "#data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#vizualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "#only required first time\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "import scipy.sparse\n",
    "\n",
    "input_location = '/Users/momori/data/reviews_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(input_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'Id', u'ProductId', u'UserId', u'ProfileName',\n",
       "       u'HelpfulnessNumerator', u'HelpfulnessDenominator', u'Score', u'Time',\n",
       "       u'Summary', u'Text', u'HelpfulnessRatio', u'avg_score',\n",
       "       u'normalized_score', u'positive_review'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create documents and labels to train the model later\n",
    "docs = data['Text']\n",
    "labels = data['positive_review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bag of words representation if one way to encode language into numerical vectors.  This happens by first creating a list of all vocabularies used by the entire dataset.  Then for each data point, the above list is initialized with all zeros, then the corresponding index's entry is incremented for each word in the data point.  <br>\n",
    "\n",
    "For example, consider the sentence 'I eat an apple' with a vocabulary list of 'I', 'eat', 'an', 'apple', 'orange'.  The cardinality of the vocabulary list is five, so there will be a 1x5 vector representation of each datapoint.  In the above example's case, the representation will be [1,1,1,1,0].  Similarly, for the sentence 'I eat eat an orange,' the representaiton would be [1,2,1,0,1].<br> \n",
    "\n",
    "The benefit of this representation is that document similarities can be calculated via cosine similarity defined as below:\n",
    "\n",
    "$$similarity = \\frac{dot\\_product(d_1, d_2)}{||d_1||*||d_2||}$$\n",
    "\n",
    "where d_1, d_2 are the encoded vectors. Intuitively, this measures the closeness of the two vectors in n-dimensional space, where n is the number of vocabularies used to encode the text.  However, the main issue with this encoding is that the order of words are not kept, so by this standard, the sentences 'cat eat rat' and 'rat eat cat' are identical.  Regardless, it is a common encoding used in NLP and will be used to create the initial baseline models.\n",
    "\n",
    "Another issue with this representation which requires some preprocessing of the data.  First off, the existence of stopwords heavily bias the resulting vectors.  For example, most sentences will have very common words such as 'the', 'a', 'an', punctuations and the likes.  These words are removed from the original data source so the models can only look at significant terms, and the stopwords are provided by the NLTK library.  Lastly, the vectorizer class used to create the bag of words representation will differentiate between terms of different cases, such as 'apple' and 'Apple.' Hence, before we start the vectorization process, the datasource will be turned into all lowercase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = keep_letters(text)\n",
    "    text = to_lower(text)\n",
    "    words = [w for w in text if not w in cached_stop_words]\n",
    "    return(\" \".join(words))\n",
    "\n",
    "def to_lower(text):\n",
    "    return [w.lower() for w in text.split()]\n",
    "\n",
    "def keep_letters(text):\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    return letters_only\n",
    "\n",
    "def calculate_accuracy(prediction, actual):\n",
    "    zipped = zip(prediction, actual)\n",
    "    acc = [i for i in zipped if i[0]==i[1]]\n",
    "    return len(acc)/float(len(zipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    bought several vitality canned dog food produc...\n",
       "1    product arrived labeled jumbo salted peanuts p...\n",
       "2    confection around centuries light pillowy citr...\n",
       "3    looking secret ingredient robitussin believe f...\n",
       "4    great taffy great price wide assortment yummy ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the text to lower case and remove stopwords\n",
    "cached_stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "reduced_text = docs.apply(remove_stopwords)\n",
    "\n",
    "reduced_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a processed dataset without punctuations, all lowerccase for easy comparison and without stopwords.  Here we will create a bag of words representation with this text using the CountVectorizer.  <br>\n",
    "\n",
    "The below CountVectorizer is part of sklearn.feature_extraction library and provides a simple way to create a sparse matrix of token counts from the original text. As seen below, the vectorizer created a matrix with the dimension (568454, 110979), where there are equivalent number of rows as the data points in the source, and recognized 110979 different vocabularies in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None) \n",
    "\n",
    "train_data_features = vectorizer.fit_transform(reduced_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 110979)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the baseline models\n",
    "\n",
    "\n",
    "Now that we have the bag of words representation for the text summaries, the goal of the below cells will be to fit a logistic regression and SVM model to measure the accuracy, to set the baseline.  The processed data will be split into a train/test split, with 70% of the data as the training set.  Then the models will be fit with the training data, and accuracy will be measured on the testing set.  Hyperparameter tuning will be done using gridsearch also. Once the optimal hyperparamers are found, a confidence interval of accuracy will be measured to statistically prove the accuracies measured in the neural network in the next notebook is significantly better or not.  To speed up the process of training multiple logistic regressions, multiprocessing module was used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 1.23 s, total: 2.45 s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#split the data\n",
    "test_size = 0.3\n",
    "\n",
    "x_train_base, x_test_base, y_train_base, y_test_base = train_test_split(\n",
    "    train_data_features, labels, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies for chosen parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'penalty': 'l1', 'max_iter': 10}</td>\n",
       "      <td>0.813810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'penalty': 'l2', 'max_iter': 10}</td>\n",
       "      <td>0.825714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'penalty': 'l1', 'max_iter': 100}</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'penalty': 'l2', 'max_iter': 100}</td>\n",
       "      <td>0.825714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               params  accuracy\n",
       "0   {'penalty': 'l1', 'max_iter': 10}  0.813810\n",
       "1   {'penalty': 'l2', 'max_iter': 10}  0.825714\n",
       "2  {'penalty': 'l1', 'max_iter': 100}  0.814286\n",
       "3  {'penalty': 'l2', 'max_iter': 100}  0.825714"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_parameters = [{'penalty':['l1','l2'], 'max_iter':[10,100]}]\n",
    "\n",
    "grid = GridSearchCV(linear_model.LogisticRegression(), lr_parameters)\n",
    "grid.fit(x_train_base, y_train_base)\n",
    "\n",
    "lr_df = pd.DataFrame(zip(grid.cv_results_['params'], grid.cv_results_['mean_test_score']), columns=['params','accuracy'])\n",
    "lr_df['params']=lr_df['params'].astype(str)\n",
    "\n",
    "print 'Accuracies for chosen parameters'\n",
    "lr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data. We will use a smaller set for the repeated tests here as the \n",
    "#training time will increase too drastically. We notice that the accuracies achieved\n",
    "#are still very similar to the model when trained with the whole dataset. \n",
    "test_size = 0.3\n",
    "\n",
    "x_train_sample, x_test_sample, y_train_sample, y_test_sample = train_test_split(\n",
    "    train_data_features[:5000], labels[:5000], test_size=test_size)\n",
    "\n",
    "num_trials = 1000\n",
    "inputs = range(num_trials)\n",
    "acc = np.empty(num_trials)\n",
    "lr = linear_model.LogisticRegression(penalty='l2', max_iter=10,solver='sag',n_jobs=-1)\n",
    "results=[]\n",
    "def do_trial(i):\n",
    "    print i,\n",
    "    lr.fit(x_train_sample, y_train_sample)\n",
    "    #acc[i] = lr.score(x_test_base, y_test_base)\n",
    "    x = lr.score(x_test_sample, y_test_sample)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.59 s, sys: 2.44 s, total: 5.02 s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import multiprocessing as mp\n",
    "import tqdm\n",
    "results = []\n",
    "pool = mp.Pool(processes=mp.cpu_count())\n",
    "results = pool.map(do_trial, inputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83733333,  0.84466667])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(results, [0.5, 99.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a SVM Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'penalty': 'l1', 'loss': 'hinge'}</td>\n",
       "      <td>0.790714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'penalty': 'l2', 'loss': 'hinge'}</td>\n",
       "      <td>0.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'penalty': 'l1', 'loss': 'log'}</td>\n",
       "      <td>0.799286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'penalty': 'l2', 'loss': 'log'}</td>\n",
       "      <td>0.794286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'penalty': 'l1', 'loss': 'squared_hinge'}</td>\n",
       "      <td>0.783571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'penalty': 'l2', 'loss': 'squared_hinge'}</td>\n",
       "      <td>0.802857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       params  accuracy\n",
       "0  {'penalty': 'l1', 'loss': 'hinge'}          0.790714\n",
       "1  {'penalty': 'l2', 'loss': 'hinge'}          0.805000\n",
       "2  {'penalty': 'l1', 'loss': 'log'}            0.799286\n",
       "3  {'penalty': 'l2', 'loss': 'log'}            0.794286\n",
       "4  {'penalty': 'l1', 'loss': 'squared_hinge'}  0.783571\n",
       "5  {'penalty': 'l2', 'loss': 'squared_hinge'}  0.802857"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_parameters = [{'penalty':['l1','l2'], 'loss':['hinge', 'log', 'squared_hinge']}]\n",
    "\n",
    "svm_grid = GridSearchCV(SGDClassifier(), svm_parameters)\n",
    "svm_grid.fit(x_train_base, y_train_base)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "svm_df = pd.DataFrame(zip(svm_grid.cv_results_['params'],svm_grid.cv_results_['mean_test_score']),columns=['params','accuracy'])\n",
    "svm_df.params = svm_df.params.astype(str)\n",
    "svm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_trials = 1000\n",
    "acc = np.empty(num_trials)\n",
    "clf = SGDClassifier(penalty='l2', loss='squared_hinge',n_jobs=-1)\n",
    "def do_trial_sv(i):\n",
    "    print i,\n",
    "    clf.fit(x_train_sample, y_train_sample)\n",
    "    #acc[i] = lr.score(x_test_base, y_test_base)\n",
    "    x = clf.score(x_test_sample, y_test_sample)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.51 s, sys: 2.52 s, total: 5.03 s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_sv = []\n",
    "pool = mp.Pool(processes=mp.cpu_count())\n",
    "results_sv = pool.map(do_trial, inputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83666667,  0.84466667])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(results_sv, [0.5, 99.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above section, we created a baseline model using the following steps <br>\n",
    "1) Use the bag of words algorithm to encode the texts into numerical vectors <br>\n",
    "2) Use logistic regression and support vector machines to tune the hyperparameters of the models.<br>\n",
    "3) fit the models on the dataset numerous times to obtain a distribution of accuracies achieved.   \n",
    "<br>\n",
    "\n",
    "Logistic regression and SVM both achieve a decent result of around 83%. \n",
    "The interesting fact to note here is that both models seems to converge rather quickly and to a similar accuracy for this dataset.  This is good bases to believe that further tuning of these models may not improve the accuracy much further.  \n",
    "\n",
    "The interesting analysis to take note here is that logistic regressions fit the dataset relatively well, which can denote that the documents and the labels fit a pretty linear relationship.  This may mean that majority of the text can be taken for what it is without sarcasm.  (If there were a lot of sarcasm and dependency on the tone of the review, then the relationship may not have been linear).  <br>\n",
    "\n",
    "We will now approach the same dataset using a different encoding algorithm and combining that with neural networks in the next notebook to measure the increase in accuracy in NeuralNets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#buffer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
