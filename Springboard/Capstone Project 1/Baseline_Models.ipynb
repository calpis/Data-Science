{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Keras on Amazon's fine food review Part 1\n",
    "## Creating baseline models\n",
    "\n",
    "To analyze how effective neural network models are for this dataset, we will be creating a logistic regression model and a SVM model as baselines to compare accuracies.  For these, the dataset will be encoded using the popular and straightforward bag of words method after removing stopwords using the list provided by nltk library.  There will also be some hyperparameter tuning to attempt at a best fit baseline models.\n",
    "\n",
    "\n",
    "   The notebook will be organized as below:\n",
    "1. Create a bag of words representation to encode the text into numerical vectors.\n",
    "2. Use the numerical vectors and fit them onto a logistic regressor and SVM.\n",
    "3. Hyperparameter tuning on the baseline models will be done using sklearn's gridsearch method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#data importing/wrangling\n",
    "import pandas as pd\n",
    "\n",
    "#text processing \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#CNN modeling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling1D, MaxPooling2D\n",
    "\n",
    "\n",
    "\n",
    "#data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#vizualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "#only required first time\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import scipy.sparse\n",
    "\n",
    "input_location = '/Users/momori/data/reviews_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(input_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'Id', u'ProductId', u'UserId', u'ProfileName',\n",
       "       u'HelpfulnessNumerator', u'HelpfulnessDenominator', u'Score', u'Time',\n",
       "       u'Summary', u'Text', u'HelpfulnessRatio', u'avg_score',\n",
       "       u'normalized_score', u'positive_review'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create documents and labels to train the model later\n",
    "docs = data['Text']\n",
    "labels = data['positive_review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bag of words representation if one way to encode language into numerical vectors.  This happens by first creating a list of all vocabularies used by the entire dataset.  Then for each data point, the above list is initialized with all zeros, then the corresponding index's entry is incremented for each word in the data point.  <br>\n",
    "\n",
    "For example, consider the sentence 'I eat an apple' with a vocabulary list of 'I', 'eat', 'an', 'apple', 'orange'.  The cardinality of the vocabulary list is five, so there will be a 1x5 vector representation of each datapoint.  In the above example's case, the representation will be [1,1,1,1,0].  Similarly, for the sentence 'I eat an orange,' the representaiton would be [1,1,1,0,1].<br>\n",
    "\n",
    "There are a few issues with this representation which requires some preprocessing of the data.  First off, the existence of stopwords heavily bias the resulting vectors.  For example, most sentences will have very common words such as 'the', 'a', 'an', punctuations and the likes.  These words are removed from the original data source so the models can only look at significant terms, and the stopwords are provided by the NLTK library.  Another point to note is that the vectorizer class used to create the bag of words representation will differentiate between terms of different cases, such as 'apple' and 'Apple.' Hence, before we start the vectorization process, the datasource will be turned into all lowercase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = keep_letters(text)\n",
    "    text = to_lower(text)\n",
    "    words = [w for w in text if not w in cached_stop_words]\n",
    "    return(\" \".join(words))\n",
    "\n",
    "def to_lower(text):\n",
    "    return [w.lower() for w in text.split()]\n",
    "\n",
    "def keep_letters(text):\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    return letters_only\n",
    "\n",
    "def calculate_accuracy(prediction, actual):\n",
    "    zipped = zip(prediction, actual)\n",
    "    acc = [i for i in zipped if i[0]==i[1]]\n",
    "    return len(acc)/float(len(zipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    bought several vitality canned dog food produc...\n",
       "1    product arrived labeled jumbo salted peanuts p...\n",
       "2    confection around centuries light pillowy citr...\n",
       "3    looking secret ingredient robitussin believe f...\n",
       "4    great taffy great price wide assortment yummy ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the text to lower case and remove stopwords\n",
    "cached_stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "reduced_text = docs.apply(remove_stopwords)\n",
    "\n",
    "reduced_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a processed dataset without punctuations, all lowerccase for easy comparison and without stopwords.  Now we will create a bag of words representation with this text using the CountVectorizer.  <br>\n",
    "\n",
    "The below CountVectorizer is part of sklearn.feature_extraction library and provides a simple way to create a sparse matrix of token counts from the original text. As seen below, the vectorizer created a matrix with the dimension (568454, 110979), where there are equivalent number of rows as the data points in the source, and recognized 110979 different vocabularies in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None) \n",
    "\n",
    "train_data_features = vectorizer.fit_transform(reduced_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 110979)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the baseline models\n",
    "\n",
    "\n",
    "Now that we have the bag of words representation for the text summaries, the goal of the below cells will be to fit a logistic regression and SVM model to measure the accuracy, to set the baseline.  The processed data will be split into a train/test split, with 70% of the data as the training set.  Then the models will be fit with the training data, and accuracy will be measured on the testing set.  Hyperparameter tuning will be done using gridsearch also.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the data\n",
    "train_size = 0.7\n",
    "\n",
    "x_train_base, x_test_base, y_train_base, y_test_base = train_test_split(\n",
    "    train_data_features, labels, test_size=train_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'penalty': ['l1', 'l2'], 'max_iter': [10, 100, 200]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_parameters = [{'penalty':['l1','l2'], 'max_iter':[10,100, 200]}]\n",
    "\n",
    "grid = GridSearchCV(linear_model.LogisticRegression(), lr_parameters)\n",
    "grid.fit(x_train_base, y_train_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.889724163813 {'penalty': 'l1', 'max_iter': 10}\n",
      "0.887859454895 {'penalty': 'l2', 'max_iter': 10}\n",
      "0.8895775672 {'penalty': 'l1', 'max_iter': 100}\n",
      "0.89036918891 {'penalty': 'l2', 'max_iter': 100}\n",
      "0.889595158793 {'penalty': 'l1', 'max_iter': 200}\n",
      "0.89036918891 {'penalty': 'l2', 'max_iter': 200}\n"
     ]
    }
   ],
   "source": [
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "\n",
    "for mean, params in zip(means,grid.cv_results_['params']):\n",
    "    print mean, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'penalty': 'l1', 'max_iter': 10}</td>\n",
       "      <td>0.889724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'penalty': 'l2', 'max_iter': 10}</td>\n",
       "      <td>0.887859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'penalty': 'l1', 'max_iter': 100}</td>\n",
       "      <td>0.889578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'penalty': 'l2', 'max_iter': 100}</td>\n",
       "      <td>0.890369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'penalty': 'l1', 'max_iter': 200}</td>\n",
       "      <td>0.889595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'penalty': 'l2', 'max_iter': 200}</td>\n",
       "      <td>0.890369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               params  accuracy\n",
       "0   {'penalty': 'l1', 'max_iter': 10}  0.889724\n",
       "1   {'penalty': 'l2', 'max_iter': 10}  0.887859\n",
       "2  {'penalty': 'l1', 'max_iter': 100}  0.889578\n",
       "3  {'penalty': 'l2', 'max_iter': 100}  0.890369\n",
       "4  {'penalty': 'l1', 'max_iter': 200}  0.889595\n",
       "5  {'penalty': 'l2', 'max_iter': 200}  0.890369"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_df = pd.DataFrame(zip(grid.cv_results_['params'], means), columns=['params','accuracy'])\n",
    "lr_df['params']=lr_df['params'].astype(str)\n",
    "lr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a SVM Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'penalty': ['l1', 'l2'], 'loss': ['hinge', 'log', 'squared_hinge']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_parameters = [{'penalty':['l1','l2'], 'loss':['hinge', 'log', 'squared_hinge']}]\n",
    "\n",
    "svm_grid = GridSearchCV(SGDClassifier(), svm_parameters)\n",
    "svm_grid.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'penalty': 'l1', 'loss': 'hinge'}</td>\n",
       "      <td>0.889724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'penalty': 'l2', 'loss': 'hinge'}</td>\n",
       "      <td>0.887859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'penalty': 'l1', 'loss': 'log'}</td>\n",
       "      <td>0.889578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'penalty': 'l2', 'loss': 'log'}</td>\n",
       "      <td>0.890369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'penalty': 'l1', 'loss': 'squared_hinge'}</td>\n",
       "      <td>0.889595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'penalty': 'l2', 'loss': 'squared_hinge'}</td>\n",
       "      <td>0.890369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       params  accuracy\n",
       "0  {'penalty': 'l1', 'loss': 'hinge'}          0.889724\n",
       "1  {'penalty': 'l2', 'loss': 'hinge'}          0.887859\n",
       "2  {'penalty': 'l1', 'loss': 'log'}            0.889578\n",
       "3  {'penalty': 'l2', 'loss': 'log'}            0.890369\n",
       "4  {'penalty': 'l1', 'loss': 'squared_hinge'}  0.889595\n",
       "5  {'penalty': 'l2', 'loss': 'squared_hinge'}  0.890369"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "svm_df = pd.DataFrame(zip(svm_grid.cv_results_['params'],means),columns=['params','accuracy'])\n",
    "svm_df.params = svm_df.params.astype(str)\n",
    "svm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above section, we created a baseline model using the following steps <br>\n",
    "1) Use the bag of words algorithm to encode the texts into numerical vectors <br>\n",
    "2) Use logistic regression and support vector machines to create a baseline model.<br>\n",
    "<br>\n",
    "\n",
    "Interestingly enough, logistic regression and SVM both achieve a very respectable accuracy of ~89%. With further parameter tuning, the accuracy may improve slightly.  The interesting analysis to take note here is that logistic regressions fit the dataset relatively well, which can denote that the documents and the labels fit a pretty linear relationship.  This may mean that majority of the text can be taken for what it is without sarcasm.  (If there were a lot of sarcasm and dependency on the tone of the review, then the relationship may not have been linear).  <br>\n",
    "\n",
    "We will now approach the same dataset using a different encoding algorithm and combining that with neural networks in the next notebook to measure the increase in accuracy in NeuralNets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#buffer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
