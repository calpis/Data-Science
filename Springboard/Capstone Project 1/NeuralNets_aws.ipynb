{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Keras on Amazon's fine food review Part 2\n",
    "\n",
    "## Using Convolutional Neural Networks\n",
    "\n",
    "This notebook will create a convolutional neural network (CNN) trained on the fine food review to suggest if the review is positive (4 or 5 star rating) or a non-positive (1, 2, or 3 star rating).  The hyperparameter tuning of the CNN will be based off of the article \"A Sensitivity Analysis of (and Practitioners' guide to) Convolutional Neural Networks for Sentence Classification.\" https://arxiv.org/pdf/1510.03820.pdf. Once the CNN is trained and used to test accuracies with the optimal hyperparameters, it will be analyzed to determine if the improvement in accuracy is significant compared to the baseline models which were created initially in the notebook Baseline_Models.ipynb.  To speed up the process of training the models, this notebook was run on an AWS p2.xlarge instance. Compared to my local laptop (macbook pro 8GB RAM), a 10-20x speed up was observed.\n",
    "\n",
    "The steps taken during this notebook are the follows:<br>\n",
    "- Read in the data and convert into a pandas dataframe.\n",
    "- The text will be turned into vectors using a combination of the tokenizer API and keras implementation of word2vec\n",
    "- distribution of the vectors will be analyzed to check for outliers and discard them as necessary.\n",
    "- short vectors will be 0-padded to match in length to the longer vectors.\n",
    "- CNNs will be trained using different parameters and performance compared amongst the other CNN models\n",
    "- After the final output model is created, accuracies will be compared with the baseline models (logistic regression and SVMs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data importing/wrangling\n",
    "import pandas as pd\n",
    "\n",
    "#text processing \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#CNN modeling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling1D, MaxPooling2D\n",
    "from keras.layers import LSTM\n",
    "\n",
    "#to suppress the epoch training outputs\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "#keras functionsl api\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "#plotting CNN\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Dense, Activation\n",
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "#data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#vizualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "#only required first time\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import scipy.sparse\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "#input_location = '/Users/momori/data/reviews_processed.csv'\n",
    "#for aws\n",
    "input_location='/home/ubuntu/data/reviews_processed.csv'\n",
    "\n",
    "model_output = '/Users/momori/data/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(input_location)\n",
    "\n",
    "#smaller sample to test code\n",
    "#data = data.sample(frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create documents and labels to train the model later\n",
    "docs = data['Text']\n",
    "labels = data['positive_review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding\n",
    "\n",
    "Here the text documents will be massaged into numerical vectors which will be fed into the keras embedding layer.  We will first use a sequence encoding of the documents to turn them into vectors, it works as follows:\n",
    "1. Count the number of vocabularies in the set of documents and creates a list such that each index in the list corresponds to a word.\n",
    "2. For each document, encode the sentence into numbers by doing a lookup onto the list and getting an interger value.\n",
    "\n",
    "For example, let's say the set of vocabulary consists of 'i', 'eat', 'apples', 'oranges'. Since there are 4 words, we create a list of size 4 and include the words as the elements:\n",
    "['i', 'eat', 'apples', 'oranges'].\n",
    "\n",
    "Now let's say we have two sentences, 'I eat apples' and 'I eat oranges.' Then these would be encoded as [1,2,3] and [1,2,4] respectively.  In comparison to word-of-bag encoding, this creates less sparse vectors which helps in the computational complexity.\n",
    "\n",
    "Once the encodings are done, we will analyze the lengths of the documents to see if there are any outliers such as very long reviews.  To feed the vectors in the neural network , all the encoded documents must be the same length, hence the shorter reviews will need to be 0-padded (adding entries of 0 at the end to match the length of the longest review). By checking the percentiles of the distribution, we may be able to remove some of the longer reviews to avoid 0-padding too much.\n",
    "\n",
    "After checking the percentiles, it was observed that we can cap the maximum length of the reviews to 200 words, as that will give us a good sense of the overall data without having to zero pad the short reviews excessively, and also is in the ~93rd percentile.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 17, 125, 319, 7, 1, 4940, 523, 103, 52, 204, 3, 17, 117, 28, 41, 5, 30, 7, 29, 183, 1, 38, 629, 48, 26, 4, 2636, 58, 4, 1183, 448, 3, 6, 619, 99, 13, 5266, 8, 1777, 3, 94, 8695, 9, 38, 99, 58, 140]\n"
     ]
    }
   ],
   "source": [
    "#use the tokenizer API provided by Keras to turn documents into sequences\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "\n",
    "#encode the documents into integers\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(encoded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a list of lengths of each of the encoded_docs to find out the longest length, \n",
    "#and see if any 0 padding is required\n",
    "doc_lengths = [len(doc) for doc in encoded_docs]\n",
    "max_doc_length = max(doc_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50  percentile of document length: 57.0\n",
      "60  percentile of document length: 70.0\n",
      "70  percentile of document length: 88.0\n",
      "80  percentile of document length: 114.0\n",
      "90  percentile of document length: 164.0\n",
      "99  percentile of document length: 398.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAD8CAYAAABAWd66AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBEEGACMIMgAYQZABwIj/Aq6TLgA+dhMVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d4c3b8490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let's put the lengths into a boxplot to see the distributions of the lengths\n",
    "np_array = np.array(doc_lengths)\n",
    "\n",
    "for i in [50,60,70,80,90,99]:\n",
    "    print i, \" percentile of document length:\", np.percentile(np_array,i)\n",
    "    \n",
    "ax = sns.boxplot(x=doc_lengths, showfliers=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8cc9866950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.4788039138\n"
     ]
    }
   ],
   "source": [
    "#let's put the lengths into a histogram to see the distributions of the lengths\n",
    "plt.hist([x for x in doc_lengths if x <= 200], bins=30)\n",
    "plt.show()\n",
    "print stats.percentileofscore(np_array, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#zero pad the shorter texts\n",
    "max_length = 200\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872496\n"
     ]
    }
   ],
   "source": [
    "#find the vocab size from tokenizer\n",
    "vocab_size = t.word_counts[max(t.word_counts,key=t.word_counts.get)]\n",
    "print vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "now that we have the data, we can split this into train/test and create a CNN using Keras.\n",
    "The CNN will be layered as follows:\n",
    "\n",
    "1. The input layer, which will just be defined along with the input shape of the data.\n",
    "2. The embedding layer. This will take as input the numerical vector encoding which was established above.  This is the first hidden layer of the network and will turn the original encoding into encoded vectors in the 'output_dimension' specified\n",
    "3. A convolutional layer which is specified with a 'filter size.'  It will look at the embedded vector by sliding the filter along the list, applying a convolution and saving the output.  For example, consider a case where the input length of this layer is a list of 50 elements and the filter size is 3.  Then, the output will be a 50-3+1 = 48 different convolutions.\n",
    "4. A pooling layer, which looks for the most significant feature in each of the convolution. In our case, we are using max-pooling, so it will look for the largest value in the convoluted results.\n",
    "5. A flatten layer, to change the dimensionality of the data into a 1-D array.\n",
    "6. output layer which will utilize a sigmoid function to determine the classification of the sample.\n",
    "    \n",
    "In addition, the below cells will make use of the article \"A Sensitivity Analysis of(and Pracitioners' Guide to) Convolustional Neural Networks for Sentence Classification\" mentioned at the top of this notebook.  The authors of the paper have tuned the various hyperparameters used in a CNN and provided the resulting best practices to optimize the search.  We will investigate some of the hyperparameters mentioned in the paper, which are filter region size, number of feature maps, and activation functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the data\n",
    "test_size = 0.3\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    padded_docs, labels, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397917, 170537)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class for convolutional neural network. Used to simplify the many \n",
    "#for loops required to go through hyper parameter tuning\n",
    "\n",
    "class cnn(object):\n",
    "    def __init__(self, vocab_size, max_doc_length,\n",
    "                 training_set_length, vect_dimensions = 4, \n",
    "                 kernel_sizes=None, activation='relu',\n",
    "                num_feature_maps = 1):\n",
    "        if kernel_sizes is None:\n",
    "            self._kernel_sizes = [5]\n",
    "        elif type(kernel_sizes) is not list:\n",
    "            self._kernel_sizes = [kernel_sizes]\n",
    "        else:\n",
    "            self._kernel_sizes = kernel_sizes\n",
    "        self._vocab_size = vocab_size\n",
    "        self._vect_dimensions = vect_dimensions\n",
    "        self._max_doc_length = max_doc_length\n",
    "        self._training_set_length = training_set_length\n",
    "        self._activation = activation\n",
    "        self._num_feature_maps = num_feature_maps\n",
    "        self._model = None\n",
    "        \n",
    "    @property\n",
    "    def vect_dimensions(self):\n",
    "        return self._vect_dimensions\n",
    "    \n",
    "    @vect_dimensions.setter\n",
    "    def vect_dimensions(self,value):\n",
    "        self._vect_dimensions = value\n",
    "    @property\n",
    "    def kernel_sizes(self):\n",
    "        return self._kernel_sizes\n",
    "    \n",
    "    @kernel_sizes.setter\n",
    "    def kernel_sizes(self, value):\n",
    "        self._kernel_sizes = value\n",
    "        \n",
    "    @property \n",
    "    def activation(self):\n",
    "        return self._activation\n",
    "    \n",
    "    @activation.setter\n",
    "    def activation(self, value):\n",
    "        if value not in ['relu','sigmoid','tanh']:\n",
    "            print 'bad activation value. defaulting to relu'\n",
    "            self._activation = 'relu'\n",
    "        else:\n",
    "            self._activation = value\n",
    "            \n",
    "    @property\n",
    "    def num_feature_maps(self):\n",
    "        return self._num_feature_maps\n",
    "    \n",
    "    @num_feature_maps.setter\n",
    "    def num_feature_maps(self, value):\n",
    "        self._num_feature_maps = value\n",
    "    \n",
    "    def list_params(self):\n",
    "        print 'filters:',self._filters\n",
    "        print 'vocab_size:', self._vocab_size\n",
    "        print 'vect_dimensions:', self._vect_dimensions\n",
    "        print 'max_doc_length:', self._max_doc_length\n",
    "        print 'training_set_length:', self._training_set_length\n",
    "        print 'kernel_size:', self._kernel_size\n",
    "        print 'activation:', self._activation\n",
    "        print 'num_feature_maps:', self._num_feature_maps\n",
    "        \n",
    "    def create(self):\n",
    "        #create the input layer\n",
    "        visible = Input(shape=(self._max_doc_length,))\n",
    "    \n",
    "        #create the embedding layer\n",
    "        x = Embedding(self._vocab_size,\n",
    "                      self._vect_dimensions, \n",
    "                      input_length=self._max_doc_length)(visible)\n",
    "        \n",
    "        #check length of filters.\n",
    "        #if more than one filter, than we branch the embedding layer into multiple layers\n",
    "        num_filters = len(self._kernel_sizes)\n",
    "        if num_filters > 1:\n",
    "            #create a list of convolutions/pools/flatten layers\n",
    "            convolutions = [None] * num_filters\n",
    "            pools = [None] * num_filters\n",
    "            flattens = [None] * num_filters\n",
    "            \n",
    "            #for each filter in self._filters, create a filter\n",
    "            for index in range(num_filters):\n",
    "                #the article suggests to use a maxpooling.\n",
    "                convolutions[index] = Conv1D(self._num_feature_maps,\n",
    "                                            kernel_size=(self._kernel_sizes[index],),\n",
    "                                            activation=self._activation,\n",
    "                                            input_shape=(self._training_set_length,))(x)\n",
    "                pools[index] = MaxPooling1D(pool_size = self._max_doc_length - \n",
    "                                            self._kernel_sizes[index] + 1)(convolutions[index])\n",
    "                flattens[index] = Flatten()(pools[index])\n",
    "        \n",
    "            #after the filters are created, merge them\n",
    "            merge = concatenate(flattens)\n",
    "            \n",
    "        else: #only 1 filter case\n",
    "            conv1 = Conv1D(self._num_feature_maps,\n",
    "                          kernel_size = (self._kernel_sizes[0],),\n",
    "                          activation=self._activation)(x)\n",
    "            pool1 = MaxPooling1D(pool_size = self._max_doc_length - self._kernel_sizes[0] + 1)(conv1)\n",
    "            merge = Flatten()(pool1)\n",
    "            \n",
    "        #after the filter layers are merged, add dense layers\n",
    "        output = Dense(1, activation='sigmoid')(merge)\n",
    "        self._model = Model(inputs = visible, outputs = output)\n",
    "\n",
    "                \n",
    "    def plot_model(self, name):\n",
    "        file_name = '/users/momori/data/models/'+str(name)+'.png'\n",
    "        print 'saving file as', file_name\n",
    "        plot_model(self._model, to_file=file_name)\n",
    "        !open $file_name\n",
    "    \n",
    "    def summarize_model(self):\n",
    "        print self._model.summary()\n",
    "    \n",
    "    def compile_fit(self, x_train, y_train, epochs=2, verbose=1):\n",
    "        #to output the training logs into a file\n",
    "        csv_logger = CSVLogger('training_log.csv', append=True, separator=';')\n",
    "\n",
    "        self._model.compile(optimizer = 'adam',\\\n",
    "                                          loss='binary_crossentropy',\n",
    "                                          metrics=['acc'])\n",
    "        print 'fitting train data into model'\n",
    "        self._model.fit(x_train, y_train, epochs=epochs,\n",
    "                                verbose=verbose, callbacks=[csv_logger])\n",
    "    \n",
    "    def evaluate(self, x_data, y_data, verbose=1):\n",
    "        loss, accuracy = self._model.evaluate(x_data, y_data, verbose=verbose)\n",
    "        return accuracy*100\n",
    "    \n",
    "    def save(self, name):\n",
    "        #file_name = '/users/momori/data/models/'+str(name)\n",
    "        #for aws\n",
    "        file_name = '/home/ubuntu/models/'+str(name)\n",
    "        print 'saving model as:', file_name\n",
    "        self._model.save(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding output dimension size analysis\n",
    "\n",
    "This was not in the original article, but will be analyzed.  The embedding output dimension size refers to the output dimension of the encoded text vectors.  The problem with large output dimension in this layer is that as the dimension is increased, the encoded vector also becomes increasingly sparse, which could hinder accuracy and performance.  But if the dimension is too small, then there will be information loss which will also lower accuracy of the model.  We aim to find the right number of output dimensions such that we see a high accuracy rate.\n",
    "\n",
    "From the below cell, the following accuracies were found. We see that the testing accuracy is the highest when the output dimension is 8 (86.47), and this seems to be a local maximium as values above and below it suffers from some accuracy loss.  In regards to training accuracy, the highest achieved was 87.90% with 24 output dimensions, but has lower testing accuracy compared to 8 dimensions. This is most likely due to the model overfitting to the training data with 24 dimensions, and hence we conclude that for this case, 8 output dimensions is the optimal value.\n",
    "\n",
    "\n",
    "| output dimension | training accuracy   | testing accuracy |\n",
    "|-------------|---------------------|------------------|\n",
    "|      2      |         85.44       |      84.54        |\n",
    "|      4      |         86.42       |       85.51      |\n",
    "|      8      |        87.75        |       86.47     |\n",
    "|      16      |       87.77         |       86.41      |\n",
    "|      24   |      87.90        |       86.40   |\n",
    "|      30     |       87.43        |       85.92      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding output dimension is: 2\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 101s - loss: 0.4184 - acc: 0.8164   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 98s - loss: 0.3652 - acc: 0.8458    \n",
      "training accuracy: 85.4404310444\n",
      "testing accuracy: 84.541770994\n",
      "saving model as: /home/ubuntu/models/model_embedding_dim_2\n",
      "\n",
      "\n",
      "embedding output dimension is: 4\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.4043 - acc: 0.8231   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.3490 - acc: 0.8542   \n",
      "training accuracy: 86.4273202703\n",
      "testing accuracy: 85.5128212646\n",
      "saving model as: /home/ubuntu/models/model_embedding_dim_4\n",
      "\n",
      "\n",
      "embedding output dimension is: 8\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 251s - loss: 0.3922 - acc: 0.8418   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 250s - loss: 0.3150 - acc: 0.8695   \n",
      "training accuracy: 87.7502092144\n",
      "testing accuracy: 86.473316641\n",
      "saving model as: /home/ubuntu/models/model_embedding_dim_8\n",
      "\n",
      "\n",
      "embedding output dimension is: 16\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 455s - loss: 0.3944 - acc: 0.8392   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 455s - loss: 0.3188 - acc: 0.8681   \n",
      "training accuracy: 87.7708165269\n",
      "testing accuracy: 86.4140919566\n",
      "saving model as: /home/ubuntu/models/model_embedding_dim_16\n",
      "\n",
      "\n",
      "embedding output dimension is: 24\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 666s - loss: 0.3932 - acc: 0.8416   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 665s - loss: 0.3187 - acc: 0.8686   \n",
      "training accuracy: 87.901245737\n",
      "testing accuracy: 86.4082281264\n",
      "saving model as: /home/ubuntu/models/model_embedding_dim_24\n",
      "\n",
      "\n",
      "embedding output dimension is: 30\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 821s - loss: 0.3984 - acc: 0.8373   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 821s - loss: 0.3261 - acc: 0.8643   \n",
      "training accuracy: 87.4302932521\n",
      "testing accuracy: 85.9215302251\n",
      "saving model as: /home/ubuntu/models/model_embedding_dim_30\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#let's use the above neural network to find the optimal window size\n",
    "vect_dimensions = [2, 4, 8, 16, 24, 30]\n",
    "for output_dim in vect_dimensions:\n",
    "    #create the CNN\n",
    "    nn = cnn(vocab_size, max_length, len(x_train), vect_dimensions=output_dim)\n",
    "    print 'embedding output dimension is:', nn.vect_dimensions\n",
    "    nn.create()\n",
    "    nn.compile_fit(x_train, y_train, epochs=2, verbose=1)\n",
    "    print 'training accuracy:', nn.evaluate(x_train, y_train, verbose=0)\n",
    "    print 'testing accuracy:',nn.evaluate(x_test, y_test, verbose=0)\n",
    "    nn.save('model_embedding_dim_'+str(output_dim))\n",
    "    print '\\n'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single kernel size analysis\n",
    "\n",
    "In the sensitivy analysis paper, the authors find that the best single filter region size is commonly found between 1 and 10. And once the best single size is found, it is recommended to try a few different combinations of different regions sizes around the best one.  The below cell will first find the single best region size.\n",
    "\n",
    "From the below cell, we've tried window size of 1-9. Here are the results:\n",
    "\n",
    "| window size | training accuracy   | testing accuracy |\n",
    "|-------------|---------------------|------------------|\n",
    "|      1      |         80.98       |      80.83       |\n",
    "|      2      |        83.38     |       83.02    |\n",
    "|      3      |        85.08       |      84.39     |\n",
    "|      4      |       86.20        |      85.30     |\n",
    "|      5      |      86.98         |       85.67      |\n",
    "|      6      |      86.86         |       85.54    |\n",
    "|      7      |        87.75       |       86.28     |\n",
    "|      8      |      87.71       |       86.29     |\n",
    "|      9      |        88.39       |       86.97     |\n",
    "\n",
    "\n",
    "We see the maximum accuracy for both training and testing when the window_size is 9. Hence we will try different number and combinations of filter size around in the next section.  Due to resource constraints on AWS, further values above 9 were not tested. In an ideal situation, values above 9 would be checked also since there is no evidence that this is the local maximum, and accuracies could still improve with increasing kernel sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel size is: [1]\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 152s - loss: 0.4753 - acc: 0.7869   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 151s - loss: 0.4488 - acc: 0.8030   \n",
      "training accuracy: 80.9832201185\n",
      "testing accuracy: 80.8346575817\n",
      "saving model as: /home/ubuntu/models/model_kernel_size1\n",
      "\n",
      "\n",
      "kernel size is: [2]\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.4358 - acc: 0.8090   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.4051 - acc: 0.8284   \n",
      "training accuracy: 83.3857311952\n",
      "testing accuracy: 83.0259709037\n",
      "saving model as: /home/ubuntu/models/model_kernel_size2\n",
      "\n",
      "\n",
      "kernel size is: [3]\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.4186 - acc: 0.8251   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.3589 - acc: 0.8455   \n",
      "training accuracy: 85.0803056916\n",
      "testing accuracy: 84.3963480066\n",
      "saving model as: /home/ubuntu/models/model_kernel_size3\n",
      "\n",
      "\n",
      "kernel size is: [4]\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.4187 - acc: 0.8259   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.3503 - acc: 0.8523   \n",
      "training accuracy: 86.2013937579\n",
      "testing accuracy: 85.3046552947\n",
      "saving model as: /home/ubuntu/models/model_kernel_size4\n",
      "\n",
      "\n",
      "kernel size is: [5]\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.4086 - acc: 0.8329   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.3350 - acc: 0.8600   \n",
      "training accuracy: 86.9882412661\n",
      "testing accuracy: 85.6693855292\n",
      "saving model as: /home/ubuntu/models/model_kernel_size5\n",
      "\n",
      "\n",
      "kernel size is: [6]\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.4150 - acc: 0.8161   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.3448 - acc: 0.8562   \n",
      "training accuracy: 86.8638434647\n",
      "testing accuracy: 85.5415540323\n",
      "saving model as: /home/ubuntu/models/model_kernel_size6\n",
      "\n",
      "\n",
      "kernel size is: [7]\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.4004 - acc: 0.8356   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.3219 - acc: 0.8668   \n",
      "training accuracy: 87.7534762272\n",
      "testing accuracy: 86.2839149276\n",
      "saving model as: /home/ubuntu/models/model_kernel_size7\n",
      "\n",
      "\n",
      "kernel size is: [8]\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.4002 - acc: 0.8332   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 148s - loss: 0.3223 - acc: 0.8654   \n",
      "training accuracy: 87.715528615\n",
      "testing accuracy: 86.2962289708\n",
      "saving model as: /home/ubuntu/models/model_kernel_size8\n",
      "\n",
      "\n",
      "kernel size is: [9]\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 149s - loss: 0.3949 - acc: 0.8372   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 149s - loss: 0.3116 - acc: 0.8716   \n",
      "training accuracy: 88.3918002999\n",
      "testing accuracy: 86.9799515648\n",
      "saving model as: /home/ubuntu/models/model_kernel_size9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#let's use the above neural network to find the optimal window size\n",
    "k_size = [i for i in range(1,10)]\n",
    "models = []\n",
    "for k in k_size:\n",
    "    #create the CNN\n",
    "    nn = cnn(vocab_size, max_length, len(x_train), \n",
    "            kernel_sizes = k)\n",
    "    print 'kernel size is:', nn.kernel_sizes\n",
    "    nn.create()\n",
    "    nn.compile_fit(x_train, y_train, epochs=2, verbose=1)\n",
    "    print 'training accuracy:', nn.evaluate(x_train, y_train, verbose=0)\n",
    "    print 'testing accuracy:',nn.evaluate(x_test, y_test, verbose=0)\n",
    "    nn.save('model_kernel_size'+str(k))\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple kernel size analysis\n",
    "\n",
    "From the above cell, we've found the best single resion size to be 9. \n",
    "Here, different combinations of multiple region sizes which are close to the best fit single region size will be used and tested.  The authors recommend testing various kernels up to a length of 3, and have come up with the below data through testing.\n",
    "\n",
    "\n",
    "| filters used | training accuracy   | testing accuracy |\n",
    "|-------------|---------------------|------------------|\n",
    "|      9     |         88.50      |      86.9      |\n",
    "|      9,9      |         88.75      |       87.19      |\n",
    "|      9,9,9      |       92.01       |       90.56     |\n",
    "|      8,9      |       91.31         |       89.80     |\n",
    "|      9,10      |     89.56          |       87.69     |\n",
    "|      8,9,10    |       91.94        |      90.42     |\n",
    "\n",
    "From the data, it can be seen that the highest training and testing accuracy is achieved with the kernel [9,9,9], with a close second to [8,9,10].  Hence we will use the filter [9,9,9] as our optimal parameter when the final model is trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel size(s) are: [9]\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 149s - loss: 0.3911 - acc: 0.8400   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 149s - loss: 0.3126 - acc: 0.8717   \n",
      "training accuracy: 88.5003656539\n",
      "testing accuracy: 86.9131039012\n",
      "saving model as: /home/ubuntu/models/model_kernel_sizes9\n",
      "\n",
      "\n",
      "kernel size(s) are: [9, 9]\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 162s - loss: 0.3688 - acc: 0.8405   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 162s - loss: 0.3047 - acc: 0.8750   \n",
      "training accuracy: 88.7544387395\n",
      "testing accuracy: 87.1951541308\n",
      "saving model as: /home/ubuntu/models/model_kernel_sizes9\n",
      "\n",
      "\n",
      "kernel size(s) are: [9, 9, 9]\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 174s - loss: 0.3146 - acc: 0.8649   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 174s - loss: 0.2302 - acc: 0.9074   \n",
      "training accuracy: 92.012153288\n",
      "testing accuracy: 90.5674428423\n",
      "saving model as: /home/ubuntu/models/model_kernel_sizes9\n",
      "\n",
      "\n",
      "kernel size(s) are: [8, 9]\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 162s - loss: 0.3240 - acc: 0.8615   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 162s - loss: 0.2465 - acc: 0.8996   \n",
      "training accuracy: 91.3107507342\n",
      "testing accuracy: 89.8063176906\n",
      "saving model as: /home/ubuntu/models/model_kernel_sizes9\n",
      "\n",
      "\n",
      "kernel size(s) are: [9, 10]\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 163s - loss: 0.3801 - acc: 0.8457   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 163s - loss: 0.2917 - acc: 0.8821   \n",
      "training accuracy: 89.5674223518\n",
      "testing accuracy: 87.6906477773\n",
      "saving model as: /home/ubuntu/models/model_kernel_sizes9\n",
      "\n",
      "\n",
      "kernel size(s) are: [8, 9, 10]\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 174s - loss: 0.3014 - acc: 0.8724   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 174s - loss: 0.2267 - acc: 0.9094   \n",
      "training accuracy: 91.9468130288\n",
      "testing accuracy: 90.4226062379\n",
      "saving model as: /home/ubuntu/models/model_kernel_sizes9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#update below accordingly to the above finding\n",
    "g_filter = 9\n",
    "\n",
    "filters = [[g_filter],[g_filter,g_filter],[g_filter,g_filter,g_filter],\n",
    "           [g_filter-1, g_filter],[g_filter, g_filter+1],\n",
    "           [g_filter-1, g_filter, g_filter+1]]\n",
    "\n",
    "\n",
    "# filters = [[g_filter,g_filter],[g_filter,g_filter,g_filter],\n",
    "#            [g_filter-1, g_filter],[g_filter, g_filter+1],\n",
    "#            [g_filter-1, g_filter, g_filter+1]]\n",
    "\n",
    "for f in filters:\n",
    "    #create the CNN\n",
    "    nn = cnn(vocab_size,max_length, len(x_train),\n",
    "            kernel_sizes = f)\n",
    "    print 'kernel size(s) are:', f\n",
    "    nn.create()\n",
    "    nn.compile_fit(x_train, y_train, epochs=2, verbose=1)\n",
    "    print 'training accuracy:', nn.evaluate(x_train, y_train, verbose=0)\n",
    "    print 'testing accuracy:',nn.evaluate(x_test, y_test, verbose=0)\n",
    "    nn.save('model_kernel_sizes'+str(k))\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis: Feature maps\n",
    "\n",
    "According to the authors, feature maps should range between 100-600. Feature maps relate to the number of mappings the convolution layer will output. For example, with a feature map value of 100, a single convolution node will output 100 maps for that particular convolution and various features of that map will be looked at. We will spot check some of recommended values and find the optimal value.\n",
    "\n",
    "From the below cell, we see that we achieve the highest testing accuracy with 700 feature maps per convolution. Similar to finding the best single kernel size, due to resource constraints no further values were checked, but in an ideal case, values beyond 700 would be checked also since we saw the highest accuracy with 700.\n",
    "\n",
    "| number of features | training accuracy   | testing accuracy |\n",
    "|-------------|---------------------|------------------|\n",
    "|      10    |        92.59       |     91.20         |\n",
    "|      50     |       93.79      |    92.22         |\n",
    "|      100      |     94.10         |    92.48         |\n",
    "|      200      |     94.35         |     92.64      |\n",
    "|      400      |     94.51         |    92.69   |\n",
    "|      600    |           94.47     |    92.69        |\n",
    "|      700    |         94.85      |      92.91       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of feature maps are: 10\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 153s - loss: 0.2884 - acc: 0.8784   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 153s - loss: 0.2156 - acc: 0.9142   \n",
      "training accuracy: 92.5926763622\n",
      "testing accuracy: 91.2007364971\n",
      "saving model as: /home/ubuntu/models/model_num_feature_maps_10\n",
      "\n",
      "\n",
      "number of feature maps are: 50\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 159s - loss: 0.2720 - acc: 0.8856   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 158s - loss: 0.1938 - acc: 0.9240   \n",
      "training accuracy: 93.798958074\n",
      "testing accuracy: 92.2239748559\n",
      "saving model as: /home/ubuntu/models/model_num_feature_maps_50\n",
      "\n",
      "\n",
      "number of feature maps are: 100\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 164s - loss: 0.2593 - acc: 0.8925   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 164s - loss: 0.1866 - acc: 0.9272   \n",
      "training accuracy: 94.1017850455\n",
      "testing accuracy: 92.4813969989\n",
      "saving model as: /home/ubuntu/models/model_num_feature_maps_100\n",
      "\n",
      "\n",
      "number of feature maps are: 200\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 174s - loss: 0.2562 - acc: 0.8934   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 173s - loss: 0.1838 - acc: 0.9286   \n",
      "training accuracy: 94.3520885009\n",
      "testing accuracy: 92.6432387107\n",
      "saving model as: /home/ubuntu/models/model_num_feature_maps_200\n",
      "\n",
      "\n",
      "number of feature maps are: 400\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 191s - loss: 0.2458 - acc: 0.8990   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 191s - loss: 0.1776 - acc: 0.9315   \n",
      "training accuracy: 94.5094077408\n",
      "testing accuracy: 92.6948404159\n",
      "saving model as: /home/ubuntu/models/model_num_feature_maps_400\n",
      "\n",
      "\n",
      "number of feature maps are: 600\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 209s - loss: 0.2478 - acc: 0.8978   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 208s - loss: 0.1779 - acc: 0.9319   \n",
      "training accuracy: 94.4689470417\n",
      "testing accuracy: 92.6948404159\n",
      "saving model as: /home/ubuntu/models/model_num_feature_maps_600\n",
      "\n",
      "\n",
      "number of feature maps are: 700\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 218s - loss: 0.2427 - acc: 0.9003   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 217s - loss: 0.1752 - acc: 0.9326   \n",
      "training accuracy: 94.8516901765\n",
      "testing accuracy: 92.9106293649\n",
      "saving model as: /home/ubuntu/models/model_num_feature_maps_700\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_maps = [10,50,100,200,400,600,700]\n",
    "for feature in feature_maps:\n",
    "    #create the CNN\n",
    "    nn = cnn(vocab_size, max_length, len(x_train),\n",
    "            num_feature_maps = feature)\n",
    "    print 'number of feature maps are:', nn.num_feature_maps\n",
    "    nn.create()\n",
    "    nn.compile_fit(x_train, y_train, epochs=2, verbose=1)\n",
    "    print 'training accuracy:', nn.evaluate(x_train, y_train, verbose=0)\n",
    "    print 'testing accuracy:',nn.evaluate(x_test, y_test, verbose=0)\n",
    "    nn.save('model_num_feature_maps_'+str(feature))\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## activation functions\n",
    "\n",
    "The authors suggest that ReLU and Tanh are usually the best performing activation functions with sigmoid following a close second.  From the below cell, it was observed that the sigmoid outperformed the other activation functions in our usecase.\n",
    "\n",
    "| activation function | training accuracy   | testing accuracy |\n",
    "|-------------|---------------------|------------------|\n",
    "|      relu    |         86.36     |      85.20        |\n",
    "|      tanh     |        86.79      |   85.53          |\n",
    "|      sigmoid     |      86.78        |   85.63          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation is: relu\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 150s - loss: 0.4039 - acc: 0.8236   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 149s - loss: 0.3526 - acc: 0.8531   \n",
      "training accuracy: 86.3662522584\n",
      "testing accuracy: 85.2084884805\n",
      "saving model as: /home/ubuntu/models/model_activation_functions_relu\n",
      "\n",
      "\n",
      "activation is: tanh\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 150s - loss: 0.4067 - acc: 0.8257   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 149s - loss: 0.3469 - acc: 0.8563   \n",
      "training accuracy: 86.7914665619\n",
      "testing accuracy: 85.5339310531\n",
      "saving model as: /home/ubuntu/models/model_activation_functions_tanh\n",
      "\n",
      "\n",
      "activation is: sigmoid\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 150s - loss: 0.4193 - acc: 0.8136   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 149s - loss: 0.3492 - acc: 0.8559   \n",
      "training accuracy: 86.7836759928\n",
      "testing accuracy: 85.6347889315\n",
      "saving model as: /home/ubuntu/models/model_activation_functions_sigmoid\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#let's use the above neural network to find the optimal window size\n",
    "activation_functions = ['relu','tanh', 'sigmoid']\n",
    "\n",
    "for func in activation_functions:\n",
    "    #create the CNN\n",
    "    nn = cnn(vocab_size, max_length, len(x_train),\n",
    "            activation = func)\n",
    "    print 'activation is:', nn.activation\n",
    "    nn.create()\n",
    "    nn.compile_fit(x_train, y_train, epochs=2, verbose=1)\n",
    "    print 'training accuracy:', nn.evaluate(x_train, y_train, verbose=0)\n",
    "    print 'testing accuracy:',nn.evaluate(x_test, y_test, verbose=0)\n",
    "    nn.save('model_activation_functions_'+str(func))\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining all the results together\n",
    "\n",
    "From the experiments, we've determined some of the optimal hyperparameters to use for this cnn.  Here we will use these parameters and observe the accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting train data into model\n",
      "Epoch 1/2\n",
      "397917/397917 [==============================] - 498s - loss: 0.2522 - acc: 0.8971   \n",
      "Epoch 2/2\n",
      "397917/397917 [==============================] - 496s - loss: 0.1744 - acc: 0.9334   \n",
      "training accuracy: 95.602851851\n",
      "testing accuracy: 93.2812234295\n",
      "saving model as: /home/ubuntu/models/out_final_model\n"
     ]
    }
   ],
   "source": [
    "activation_fun = 'sigmoid'\n",
    "num_feature_maps = 700\n",
    "kernel_sizes = [9,9,9]\n",
    "vect_dimensions = 8\n",
    "\n",
    "nn = cnn(vocab_size, max_length, len(x_train), vect_dimensions = vect_dimensions,\n",
    "        activation = activation_fun, num_feature_maps = num_feature_maps,\n",
    "        kernel_sizes = kernel_sizes)\n",
    "nn.create()\n",
    "nn.compile_fit(x_train, y_train, epochs=2, verbose=1)\n",
    "print 'training accuracy:', nn.evaluate(x_train, y_train, verbose=0)\n",
    "print 'testing accuracy:',nn.evaluate(x_test, y_test, verbose=0)\n",
    "nn.save('out_final_model')\n",
    "\n",
    "#nn.plot_model('final_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve a very high 95.60% training accuracy  and a testing accuracy of 93.28%.  This is much better than the ~83% testing accuracy achieved by the baseline models. \n",
    "As a reminder the 99% confidence interval for accuracies achieved are below:\n",
    "\n",
    "| model | testing accuracy   | \n",
    "|-------------|---------------------|\n",
    "|      Logistic Regression    |         [ 0.83733333,  0.84466667]    | \n",
    "|      SVM     |        [ 0.83666667,  0.84466667]      |  \n",
    "\n",
    "This shows that there is statistically significant improvement by using CNNs over the baseline models for this dataset.  This neural network is not too deep, but already looks at millions of different varieties of parameters from the data source and does a much better job of drawing the boundary line to classify this dataset.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#buffer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
