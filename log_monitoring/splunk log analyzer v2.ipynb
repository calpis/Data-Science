{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from functions.ipynb\n",
      "Importing Jupyter notebook from functions.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import nbimporter\n",
    "import functions\n",
    "reload(functions)\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "#viz\n",
    "from datetime import date\n",
    "from random import randint\n",
    "import math\n",
    "\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.models.widgets import DataTable, DateFormatter, TableColumn\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.models.tickers import FixedTicker\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from dateutil import parser\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.stattools import arma_order_select_ic\n",
    "from matplotlib import pyplot\n",
    "\n",
    "#from bokeh.io import vform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##variables\n",
    "look_back = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/momori/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (0,1,2,4,5,6,7,8,10,11,12,13,14,15,18,19,20,21,22,23,25,26,28,29,30,31,33,34,36,38,40,41,42,45,46,48,49,50,52,53,54,55,56,57,59,60,63,64,65,68,69,70,72,73,74,75,76,77,79,80,81,82,83,87,89,90,91,100,101,102,105,107,108,109,110,111,112,114,115,116,117,119,122,123,124,126,127,128,129,130,131,133,135,136,137,139,142,143,144,145,146,148,149,150,154,155,156,158,159,160,161,169,171,172,173,174,175,176,177,178,179,181,183,184,185,186,194,196,198,200,201,202,204,209,214,217,218,219,220,224,225,227,229,230,231,232,233,234,235,238,242,243) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "log_file = '/Users/momori/Documents/projects/log_monitoring/muleprep_app_ERROR.csv'\n",
    "log_file1 = '/Users/momori/Documents/projects/log_monitoring/muleprod_app_aug_7.csv'\n",
    "log_file2 = '/Users/momori/Documents/projects/log_monitoring/muleprod_app_aug_1.csv'\n",
    "log_file3 = '/Users/momori/Documents/projects/log_monitoring/muleprep_app_ERROR.csv'\n",
    "log_file4 = '/Users/momori/Documents/projects/log_monitoring/muleprep_app_ERROR.csv'\n",
    "\n",
    "df_test = pd.read_csv(log_file)\n",
    "df_train1 = pd.read_csv(log_file)#1)\n",
    "df_train2 = pd.read_csv(log_file)#2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = [df_train1, df_train2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##km: clustering model\n",
    "##vecetorizer: document vectorizer\n",
    "##document: document to cluster\n",
    "def predict_document_cluster(km, vectorizer, document):\n",
    "    doc = vectorizer.transform([document])\n",
    "    return km.predict(doc)\n",
    "\n",
    "def format_df(df):\n",
    "    r_df = df.dropna(axis=1)\n",
    "    r_df.loc[:,'_time'] = r_df['_time'].apply(lambda x: format_time(x))\n",
    "    return r_df\n",
    "\n",
    "def format_time(string):\n",
    "    ##may need smarter logic. seems slow\n",
    "    return parser.parse(string)\n",
    "\n",
    "##step_time in minutes\n",
    "##\n",
    "## returns: dict. key is timestamp, value is dataframe\n",
    "def split_by_time(df, step_time=30):\n",
    "    r_dict = {}\n",
    "    t=str(step_time)+'Min'\n",
    "    \n",
    "    #set _time to index\n",
    "    tmp = df.set_index(1)\n",
    "    tmp = tmp.groupby(pd.TimeGrouper(freq=t))\n",
    "    for key, item in tmp:\n",
    "        try:\n",
    "            r_dict[str(key)] = tmp.get_group(key)\n",
    "        except:\n",
    "            continue\n",
    "    return r_dict\n",
    "        \n",
    "def show_top_words(km, vect, show=False, save=True, out_filename='output'):\n",
    "    dcluster_words = {}\n",
    "    if show:\n",
    "        print(\"Top terms per cluster:\")\n",
    "\n",
    "    order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "    terms = vect.get_feature_names()\n",
    "    for i in range(k):\n",
    "        if show:\n",
    "            print(\"Cluster %d:\" % i)\n",
    "            for ind in order_centroids[i, :10]:\n",
    "                print(' %s' % terms[ind])\n",
    "        if save:\n",
    "            words = []\n",
    "            for ind in order_centroids[i, :10]:\n",
    "                words.append(terms[ind])\n",
    "            dcluster_words[i] = words\n",
    "    if save:\n",
    "        np.save(out_filename, dcluster_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb               lowerbound.npy\r\n",
      "Untitled1.ipynb              module_test.ipynb\r\n",
      "bollinger.html               new_df_formatted\r\n",
      "check_logs                   new_logs\r\n",
      "cluster_num.npy              output.npy\r\n",
      "cluster_words                splunk log analyzer v2.ipynb\r\n",
      "counts.npy                   splunk log analyzer.ipynb\r\n",
      "data_table.html              splunk_log_analyzer_v3.ipynb\r\n",
      "functions.ipynb              splunk_viz.ipynb\r\n",
      "intuit.html                  times\r\n",
      "line_bar.html                times.npy\r\n",
      "log_analysis_tutorial.ipynb  upperbound.npy\r\n",
      "log_cleaning.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "#show_top_words(km, vect, save=True)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# d = np.load('output.npy').item()\n",
    "# for k,v1 in d.iteritems():\n",
    "#     print k,v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logs_train1 = df_train1['_raw'].tolist()\n",
    "logs_train2 = df_train2['_raw'].tolist()\n",
    "logs_test = df_test['_raw'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Fit a vectorizer\n",
    "vect = TfidfVectorizer(max_df = 0.5, min_df = 2, stop_words='english')\n",
    "\n",
    "#v is base vectorizer, can be used to transform other logs\n",
    "v = vect.fit(logs_train1)\n",
    "\n",
    "#x is the tfidf sparse matrix created for this set of logs\n",
    "x1 = v.transform(logs_train1)\n",
    "x2 = v.transform(logs_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(batch_size=1000, compute_labels=True, init='k-means++',\n",
       "        init_size=1000, max_iter=100, max_no_improvement=10, n_clusters=20,\n",
       "        n_init=1, random_state=None, reassignment_ratio=0.01, tol=0.0,\n",
       "        verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##create kmeans model and fit\n",
    "k=20\n",
    "km = MiniBatchKMeans(n_clusters=k, init='k-means++', n_init=1,\n",
    "                         init_size=1000, batch_size=1000)\n",
    "km.fit(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " java\n",
      " component\n",
      " groovy\n",
      " scriptcomponent\n",
      " common\n",
      " codehaus\n",
      " accounts\n",
      " 903970365\n",
      " v1\n",
      " eval\n",
      "Cluster 1:\n",
      " entitlement\n",
      " commerce\n",
      " 01\n",
      " entitlementofferingrestransformer\n",
      " entitledoffering\n",
      " connectorwithoutmulesession\n",
      " cas\n",
      " transformer\n",
      " services\n",
      " received\n",
      "Cluster 2:\n",
      " accountconversionapi\n",
      " 123146541871034\n",
      " internal\n",
      " websenhanceddataexception\n",
      " 414\n",
      " exist\n",
      " does\n",
      " requested\n",
      " resource\n",
      " cdata\n",
      "Cluster 3:\n",
      " grizzly\n",
      " glassfish\n",
      " safefutureimpl\n",
      " singleendpointpool\n",
      " java\n",
      " abstractthreadpool\n",
      " impl\n",
      " thread\n",
      " dowork\n",
      " connectionpool\n",
      "Cluster 4:\n",
      " catalog\n",
      " offers\n",
      " invokerestorchestration\n",
      " txid\n",
      " offer\n",
      " connector\n",
      " flow\n",
      " default\n",
      " app\n",
      " karthik_iamtestpass_710283333\n",
      "Cluster 5:\n",
      " followredirects\n",
      " redirect\n",
      " httpclientmessagedispatcher\n",
      " 500\n",
      " httpsconnector\n",
      " internal\n",
      " router\n",
      " server\n",
      " tbt\n",
      " transport\n",
      "Cluster 6:\n",
      " jar\n",
      " core\n",
      " execute\n",
      " execution\n",
      " java\n",
      " exceptiontomessagingexceptionexecutioninterceptor\n",
      " messageprocessornotificationexecutioninterceptor\n",
      " blockingprocessorexecutor\n",
      " process\n",
      " messageprocessorexecutiontemplate\n",
      "Cluster 7:\n",
      " java\n",
      " 0_112\n",
      " ssl\n",
      " sslsocketimpl\n",
      " security\n",
      " jar\n",
      " transport\n",
      " httpserverconnection\n",
      " httpclient\n",
      " commons\n",
      "Cluster 8:\n",
      " restrictions\n",
      " rps\n",
      " ebcs\n",
      " properties\n",
      " screenpartyresponse\n",
      " vm\n",
      " scoped\n",
      " 11e7\n",
      " aa1zcqb\n",
      " application\n",
      "Cluster 9:\n",
      " ns2\n",
      " quot\n",
      " xmlns\n",
      " schema\n",
      " intuit\n",
      " 1000\n",
      " obillstatus\n",
      " obillstatusdate\n",
      " accountcontext\n",
      " legacystatusdate\n",
      "Cluster 10:\n",
      " limit\n",
      " offset\n",
      " 64\n",
      " accountid\n",
      " getaccounts\n",
      " accounts\n",
      " v1\n",
      " websgetaccountsapi\n",
      " uri\n",
      " 404\n",
      "Cluster 11:\n",
      " java\n",
      " component\n",
      " common\n",
      " groovy\n",
      " scriptcomponent\n",
      " accounts\n",
      " 1107246113\n",
      " codehaus\n",
      " v1\n",
      " eval\n",
      "Cluster 12:\n",
      " sub\n",
      " xxxx\n",
      " comcus\n",
      " comfin\n",
      " xmlns\n",
      " phone\n",
      " billingservicetype\n",
      " entitledproductid\n",
      " subscription\n",
      " schema\n",
      "Cluster 13:\n",
      " cache\n",
      " user_id\n",
      " http\n",
      " properties\n",
      " realm_id\n",
      " content\n",
      " scoped\n",
      " ticket\n",
      " ebpi\n",
      " gmt\n",
      "Cluster 14:\n",
      " xmlns\n",
      " ns3\n",
      " schema\n",
      " intuit\n",
      " http\n",
      " envelope\n",
      " com\n",
      " ns0\n",
      " platform\n",
      " soap\n",
      "Cluster 15:\n",
      " entitlement\n",
      " commerce\n",
      " 06\n",
      " entitlementofferingrestransformer\n",
      " entitledoffering\n",
      " connectorwithoutmulesession\n",
      " cas\n",
      " transformer\n",
      " services\n",
      " received\n",
      "Cluster 16:\n",
      " accountconversionapi\n",
      " internal\n",
      " conversionorchestrationflow\n",
      " flowname\n",
      " processor\n",
      " loggermessageprocessor\n",
      " getaccounts\n",
      " intuit_tid\n",
      " data\n",
      " 18\n",
      "Cluster 17:\n",
      " eventsource\n",
      " encountered\n",
      " streamprocessor\n",
      " reset\n",
      " okhttp\n",
      " launchdarkly\n",
      " connection\n",
      " client\n",
      " com\n",
      " 51\n",
      "Cluster 18:\n",
      " accountconversionapi\n",
      " internal\n",
      " websenhanceddataexception\n",
      " 414\n",
      " exist\n",
      " does\n",
      " requested\n",
      " resource\n",
      " cdata\n",
      " moreinfo\n",
      "Cluster 19:\n",
      " header\n",
      " violations\n",
      " intuit_originatingip\n",
      " headers\n",
      " validation\n",
      " headerfilter\n",
      " total\n",
      " number\n",
      " directsignupapi\n",
      " 16\n"
     ]
    }
   ],
   "source": [
    "##Let's use cluster 6 as it shows '500' as one of the top words\n",
    "show_top_words(km, vect, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in range(20):\n",
    "#    print i, len(df_predict1[df_predict1[2]==i]), len(df_predict2[df_predict2[2]==i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/momori/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFO  2017-08-19 14:18:11,732 [[ebcs-restricti...</td>\n",
       "      <td>2017-08-19 14:18:11.732000-07:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-19 14:18:09,124 | level=ERROR| thread=...</td>\n",
       "      <td>2017-08-19 14:18:09.124000-07:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-19 14:17:48,122 | level=ERROR| thread=...</td>\n",
       "      <td>2017-08-19 14:17:48.122000-07:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFO  2017-08-19 14:17:47,376 [[webs-pub-conve...</td>\n",
       "      <td>2017-08-19 14:17:47.376000-07:00</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFO  2017-08-19 14:17:47,374 [[webs-pub-conve...</td>\n",
       "      <td>2017-08-19 14:17:47.374000-07:00</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  INFO  2017-08-19 14:18:11,732 [[ebcs-restricti...   \n",
       "1  2017-08-19 14:18:09,124 | level=ERROR| thread=...   \n",
       "2  2017-08-19 14:17:48,122 | level=ERROR| thread=...   \n",
       "3  INFO  2017-08-19 14:17:47,376 [[webs-pub-conve...   \n",
       "4  INFO  2017-08-19 14:17:47,374 [[webs-pub-conve...   \n",
       "\n",
       "                                 1   2  \n",
       "0 2017-08-19 14:18:11.732000-07:00   8  \n",
       "1 2017-08-19 14:18:09.124000-07:00   3  \n",
       "2 2017-08-19 14:17:48.122000-07:00   3  \n",
       "3 2017-08-19 14:17:47.376000-07:00  18  \n",
       "4 2017-08-19 14:17:47.374000-07:00  18  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##get predictions for a subset of the logs and create df with _raw, _time, and label\n",
    "formatted_df = format_df(df_train1)\n",
    "\n",
    "logs = formatted_df['_raw'].tolist()\n",
    "times = formatted_df['_time'].tolist()\n",
    "test_x1 = v.transform(logs)\n",
    "\n",
    "labels = km.predict(test_x1)\n",
    "lst = zip(logs, times, labels.tolist())\n",
    "df_predict1 = pd.DataFrame(lst)\n",
    "df_predict1.head()\n",
    "\n",
    "##do same for second train set\n",
    "formatted_df = format_df(df_train2)\n",
    "\n",
    "logs = formatted_df['_raw'].tolist()\n",
    "times = formatted_df['_time'].tolist()\n",
    "test_x2 = v.transform(logs)\n",
    "\n",
    "labels = km.predict(test_x2)\n",
    "lst = zip(logs, times, labels.tolist())\n",
    "df_predict2 = pd.DataFrame(lst)\n",
    "df_predict2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118716, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##for each cluster number, create a dt\n",
    "#df_clusters1, df_clusters2 = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFO  2017-08-19 14:18:11,732 [[ebcs-restricti...</td>\n",
       "      <td>2017-08-19 14:18:11.732000-07:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>INFO  2017-08-19 14:07:15,740 [[ebcs-restricti...</td>\n",
       "      <td>2017-08-19 14:07:15.740000-07:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>INFO  2017-08-19 14:07:11,816 [[ebcs-restricti...</td>\n",
       "      <td>2017-08-19 14:07:11.816000-07:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>INFO  2017-08-19 14:06:05,157 [[ebcs-restricti...</td>\n",
       "      <td>2017-08-19 14:06:05.157000-07:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>INFO  2017-08-19 13:35:53,037 [[ebcs-restricti...</td>\n",
       "      <td>2017-08-19 13:35:53.037000-07:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0  \\\n",
       "0     INFO  2017-08-19 14:18:11,732 [[ebcs-restricti...   \n",
       "667   INFO  2017-08-19 14:07:15,740 [[ebcs-restricti...   \n",
       "668   INFO  2017-08-19 14:07:11,816 [[ebcs-restricti...   \n",
       "724   INFO  2017-08-19 14:06:05,157 [[ebcs-restricti...   \n",
       "2530  INFO  2017-08-19 13:35:53,037 [[ebcs-restricti...   \n",
       "\n",
       "                                    1  2  \n",
       "0    2017-08-19 14:18:11.732000-07:00  8  \n",
       "667  2017-08-19 14:07:15.740000-07:00  8  \n",
       "668  2017-08-19 14:07:11.816000-07:00  8  \n",
       "724  2017-08-19 14:06:05.157000-07:00  8  \n",
       "2530 2017-08-19 13:35:53.037000-07:00  8  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_num = 8\n",
    "f_df1 = df_predict1[df_predict1[2]==cluster_num]\n",
    "f_df2 = df_predict2[df_predict2[2]==cluster_num]\n",
    "#f_df1 = df_predict1\n",
    "#f_df2 = df_predict2\n",
    "f_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_logs = f_df1[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "check_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Create dictionary of dataframes, split by time\n",
    "d1 = OrderedDict(sorted(split_by_time(f_df1).items()))\n",
    "d2 = OrderedDict(sorted(split_by_time(f_df2).items()))\n",
    "#d1 = OrderedDict(sorted(split_by_time(df_predict1).items()))\n",
    "#d2 = OrderedDict(sorted(split_by_time(df_predict2).items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create counts for training\n",
    "counts1 = []\n",
    "counts2 = []\n",
    "for k, val in d1.iteritems():\n",
    "    counts1.append(val.shape[0])\n",
    "for k, val in d2.iteritems():\n",
    "    counts2.append(val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts1), len(counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([11, 231, 342, 152, 64, 264, 56, 33, 56, 72],\n",
       " [11, 231, 342, 152, 64, 264, 56, 33, 56, 72])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts1[:10], counts2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<118716x56347 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 6591783 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = vect.fit(logs_train1)\n",
    "v.transform(logs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFO  2017-08-19 14:18:11,732 [[ebcs-restricti...</td>\n",
       "      <td>2017-08-19 14:18:11.732000-07:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-19 14:18:09,124 | level=ERROR| thread=...</td>\n",
       "      <td>2017-08-19 14:18:09.124000-07:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-19 14:17:48,122 | level=ERROR| thread=...</td>\n",
       "      <td>2017-08-19 14:17:48.122000-07:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFO  2017-08-19 14:17:47,376 [[webs-pub-conve...</td>\n",
       "      <td>2017-08-19 14:17:47.376000-07:00</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFO  2017-08-19 14:17:47,374 [[webs-pub-conve...</td>\n",
       "      <td>2017-08-19 14:17:47.374000-07:00</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  INFO  2017-08-19 14:18:11,732 [[ebcs-restricti...   \n",
       "1  2017-08-19 14:18:09,124 | level=ERROR| thread=...   \n",
       "2  2017-08-19 14:17:48,122 | level=ERROR| thread=...   \n",
       "3  INFO  2017-08-19 14:17:47,376 [[webs-pub-conve...   \n",
       "4  INFO  2017-08-19 14:17:47,374 [[webs-pub-conve...   \n",
       "\n",
       "                                 1   2  \n",
       "0 2017-08-19 14:18:11.732000-07:00   8  \n",
       "1 2017-08-19 14:18:09.124000-07:00   3  \n",
       "2 2017-08-19 14:17:48.122000-07:00   3  \n",
       "3 2017-08-19 14:17:47.376000-07:00  18  \n",
       "4 2017-08-19 14:17:47.374000-07:00  18  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Let's fit the 'future' data and pull out cluster_num\n",
    "formatted_df = format_df(df_test)\n",
    "logs_test = formatted_df['_raw'].tolist()\n",
    "times = formatted_df['_time'].tolist()\n",
    "test_x1 = v.transform(logs_test)\n",
    "\n",
    "labels = km.predict(test_x1)\n",
    "lst = zip(logs, times, labels.tolist())\n",
    "test_data = pd.DataFrame(lst)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = test_data[test_data[2]==cluster_num]\n",
    "\n",
    "#test_data = test_data\n",
    "test_d = OrderedDict(sorted(split_by_time(test_data).items()))\n",
    "test_counts = []\n",
    "for k, val in test_d.iteritems():\n",
    "    test_counts.append(val.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFO  2017-08-19 14:18:11,732 [[ebcs-restricti...</td>\n",
       "      <td>2017-08-19 14:18:11.732000-07:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>INFO  2017-08-19 14:07:15,740 [[ebcs-restricti...</td>\n",
       "      <td>2017-08-19 14:07:15.740000-07:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>INFO  2017-08-19 14:07:11,816 [[ebcs-restricti...</td>\n",
       "      <td>2017-08-19 14:07:11.816000-07:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>INFO  2017-08-19 14:06:05,157 [[ebcs-restricti...</td>\n",
       "      <td>2017-08-19 14:06:05.157000-07:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>INFO  2017-08-19 13:35:53,037 [[ebcs-restricti...</td>\n",
       "      <td>2017-08-19 13:35:53.037000-07:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0  \\\n",
       "0     INFO  2017-08-19 14:18:11,732 [[ebcs-restricti...   \n",
       "667   INFO  2017-08-19 14:07:15,740 [[ebcs-restricti...   \n",
       "668   INFO  2017-08-19 14:07:11,816 [[ebcs-restricti...   \n",
       "724   INFO  2017-08-19 14:06:05,157 [[ebcs-restricti...   \n",
       "2530  INFO  2017-08-19 13:35:53,037 [[ebcs-restricti...   \n",
       "\n",
       "                                    1  2  \n",
       "0    2017-08-19 14:18:11.732000-07:00  8  \n",
       "667  2017-08-19 14:07:15.740000-07:00  8  \n",
       "668  2017-08-19 14:07:11.816000-07:00  8  \n",
       "724  2017-08-19 14:06:05.157000-07:00  8  \n",
       "2530 2017-08-19 13:35:53.037000-07:00  8  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 231, 342, 152, 64, 264, 56, 33, 56, 72]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "#zip the data\n",
    "counts1 = [float(i) for i in counts1]\n",
    "counts2 = [float(i) for i in counts2]\n",
    "\n",
    "train = zip(counts1, counts2)\n",
    "train = [i for i in train if math.fabs(i[1]-i[0] < 100)]\n",
    "print len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11.0, 11.0),\n",
       " (231.0, 231.0),\n",
       " (342.0, 342.0),\n",
       " (152.0, 152.0),\n",
       " (64.0, 64.0),\n",
       " (264.0, 264.0),\n",
       " (56.0, 56.0),\n",
       " (33.0, 33.0),\n",
       " (56.0, 56.0),\n",
       " (72.0, 72.0),\n",
       " (273.0, 273.0),\n",
       " (36.0, 36.0),\n",
       " (147.0, 147.0),\n",
       " (247.0, 247.0),\n",
       " (47.0, 47.0),\n",
       " (54.0, 54.0),\n",
       " (10.0, 10.0),\n",
       " (11.0, 11.0),\n",
       " (166.0, 166.0),\n",
       " (310.0, 310.0),\n",
       " (177.0, 177.0),\n",
       " (100.0, 100.0),\n",
       " (49.0, 49.0),\n",
       " (330.0, 330.0),\n",
       " (231.0, 231.0),\n",
       " (17.0, 17.0),\n",
       " (179.0, 179.0),\n",
       " (356.0, 356.0),\n",
       " (222.0, 222.0),\n",
       " (291.0, 291.0),\n",
       " (27.0, 27.0),\n",
       " (2.0, 2.0),\n",
       " (8.0, 8.0),\n",
       " (2.0, 2.0),\n",
       " (1.0, 1.0),\n",
       " (3.0, 3.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (6.0, 6.0),\n",
       " (28.0, 28.0),\n",
       " (1.0, 1.0),\n",
       " (11.0, 11.0),\n",
       " (3.0, 3.0),\n",
       " (7.0, 7.0),\n",
       " (22.0, 22.0),\n",
       " (15.0, 15.0),\n",
       " (1.0, 1.0),\n",
       " (4.0, 4.0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "##make predictions by fitting ARIMA model into the lists\n",
    "prediction_upperbound = []\n",
    "prediction_lowerbound = []\n",
    "prediction_value = []\n",
    "\n",
    "for t in train:\n",
    "    rgr = ARIMA(t, order=(0,0,0))\n",
    "    fit = rgr.fit(disp=0)\n",
    "    forecast =  fit.forecast()\n",
    "    prediction_upperbound.append(forecast[2][0][1])\n",
    "    prediction_lowerbound.append(forecast[2][0][0])\n",
    "    prediction_value.append(forecast[0])\n",
    "\n",
    "#Turn into numpy array for computation\n",
    "prediction_upperbound = np.asarray(prediction_upperbound)\n",
    "prediction_lowerbound = np.asarray(prediction_lowerbound)\n",
    "prediction_value = np.asarray(prediction_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/momori/anaconda2/lib/python2.7/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 47), ('y', 48)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 94), ('y', 96)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "\n",
    "# Define Bollinger Bands.\n",
    "upperband = prediction_upperbound\n",
    "lowerband = prediction_lowerbound\n",
    "x_data = np.arange(1, 101)\n",
    "\n",
    "length = min(len(prediction_upperbound), len(prediction_lowerbound))\n",
    "x_data = np.arange(1, length)\n",
    "# Bollinger shading glyph:\n",
    "band_x = np.append(x_data, x_data[::-1])\n",
    "band_y = np.append(lowerband, upperband[::-1])\n",
    "\n",
    "output_file('bollinger.html', title='Bollinger bands (file)')\n",
    "\n",
    "\n",
    "p = figure(x_axis_type='datetime', title=\"\")\n",
    "\n",
    "# add a line renderer\n",
    "p.line([i for i in range(1,length)], counts2, line_width=2)\n",
    "p.grid.grid_line_alpha = 0.4\n",
    "p.x_range.range_padding = 0\n",
    "p.plot_height = 600\n",
    "p.plot_width = 800\n",
    "\n",
    "p.patch(band_x, band_y, color='#7570B3', fill_alpha=0.2)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = '/Users/momori/PycharmProjects/AIMonitoring/data/qq.csv'\n",
    "dd = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/momori/anaconda2/lib/python2.7/site-packages/bokeh/models/sources.py:91: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 13), ('y', 14)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/Users/momori/anaconda2/lib/python2.7/site-packages/bokeh/models/sources.py:91: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 26), ('y', 28)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "\n",
    "# Define Bollinger Bands.\n",
    "upperband = prediction_upperbound\n",
    "lowerband = prediction_lowerbound\n",
    "x_data = np.arange(1, 101)\n",
    "\n",
    "length = min(len(prediction_upperbound), len(prediction_lowerbound))\n",
    "x_data = np.arange(1, length)\n",
    "# Bollinger shading glyph:\n",
    "band_x = np.append(x_data, x_data[::-1])\n",
    "band_y = np.append(lowerband, upperband[::-1])\n",
    "\n",
    "output_file('bollinger.html', title='Bollinger bands (file)')\n",
    "\n",
    "\n",
    "p = figure(x_axis_type='datetime', title=\"\")\n",
    "\n",
    "# add a line renderer\n",
    "p.line([i for i in range(1,length)], counts2, line_width=2)\n",
    "p.grid.grid_line_alpha = 0.4\n",
    "p.x_range.range_padding = 0\n",
    "p.plot_height = 600\n",
    "p.plot_width = 800\n",
    "\n",
    "p.patch(band_x, band_y, color='#7570B3', fill_alpha=0.2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p.xaxis.ticker = FixedTicker(ticks=times)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##get predictions for a subset of the logs and create df with _raw, _time, and label\n",
    "test_df = format_df(df[0:10000])\n",
    "\n",
    "logs = test_df['_raw'].tolist()\n",
    "times = test_df['_time'].tolist()\n",
    "test_x = vect.transform(logs)\n",
    "\n",
    "labels = km.predict(test_x)\n",
    "lst = zip(logs,times,labels.tolist())\n",
    "df_predict = pd.DataFrame(lst)\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Create dictionary of dataframes, split by time\n",
    "d = split_by_time(df_predict)\n",
    "for k,v in d.iteritems():\n",
    "    print k, ':::', type(v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d['2017-08-19 13:00:00-07:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Cluster the interval logs by using km.  \n",
    "#Then get the count for predicting outcomes.\n",
    "\n",
    "#test out on d\n",
    "counts = []\n",
    "for k, v in d.iteritems():\n",
    "    print k\n",
    "    counts.append(v.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##train gradient boosted trees for regression\n",
    "params = {'n_estimators': 10, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "clf = ensemble.GradientBoostingRegressor(**params)\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use an ARIMA Model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "floats = [float(i) for i in counts]\n",
    "floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rgr = ARIMA(floats[:len(floats)-1], order=(0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit = rgr.fit(disp=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit.forecast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "\n",
    "# Define Bollinger Bands.\n",
    "upperband = np.random.random_integers(100, 150, size=100)\n",
    "lowerband = upperband - 100\n",
    "x_data = np.arange(1, 101)\n",
    "\n",
    "# Bollinger shading glyph:\n",
    "band_x = np.append(x_data, x_data[::-1])\n",
    "band_y = np.append(lowerband, upperband[::-1])\n",
    "\n",
    "output_file('bollinger.html', title='Bollinger bands (file)')\n",
    "\n",
    "\n",
    "p = figure(x_axis_type='datetime', title=\"Bollinger Bands\")\n",
    "\n",
    "# add a line renderer\n",
    "p.line([0, 20, 30, 40, 50], [80, 130, 135, 90, 90], line_width=4)\n",
    "p.grid.grid_line_alpha = 0.4\n",
    "p.x_range.range_padding = 0\n",
    "p.plot_height = 600\n",
    "p.plot_width = 800\n",
    "\n",
    "p.patch(band_x, band_y, color='#7570B3', fill_alpha=0.2)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from bokeh.plotting import figure, output_file, show\n",
    "# from bokeh.models.ranges import Range1d\n",
    "# import numpy\n",
    "\n",
    "\n",
    "# output_file(\"line_bar.html\")\n",
    "\n",
    "# p = figure(plot_width=400, plot_height=400)\n",
    "\n",
    "# # add a line renderer\n",
    "# p.line([1, 2, 3, 4, 5], [6, 7, 6, 4, 5], line_width=2)\n",
    "\n",
    "# # setting bar values\n",
    "# h = numpy.array([2, 8, 5, 10, 7])\n",
    "\n",
    "# # Correcting the bottom position of the bars to be on the 0 line.\n",
    "# adj_h = h/2\n",
    "\n",
    "# # add bar renderer\n",
    "# p.rect(x=[1, 2, 3, 4, 5], y=adj_h, width=0.4, height=h, color=\"#CAB2D6\")\n",
    "\n",
    "# # Setting the y  axis range   \n",
    "# p.y_range = Range1d(0, 12)\n",
    "\n",
    "# #p.title = \"Line and Bar\"\n",
    "\n",
    "# show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from bokeh.plotting import figure, output_file, show\n",
    "# from bokeh.models.ranges import Range1d\n",
    "# import numpy\n",
    "\n",
    "\n",
    "# output_file(\"line_bar.html\")\n",
    "# p = figure(plot_width=400, plot_height=400)\n",
    "\n",
    "# p.line([1, 2, 3, 4, 5], [6, 7, 6, 4, 5], line_width=2)\n",
    "\n",
    "\n",
    "# show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
